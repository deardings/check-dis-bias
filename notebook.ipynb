{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung der ECVs:\n",
    "\n",
    "disabilities = [\"Disability\", \"Depression\", \"Autism\", \"Blind\", \"Deaf\", \"Cerebral Palsy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f94c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_6820e443470c8191835fa06edeac7ff901500285876f2f6b', created_at=1746986051.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='o3-2025-04-16', object='response', output=[ResponseReasoningItem(id='rs_6820e443a6f88191a5fcd5d25f1554a101500285876f2f6b', summary=[], type='reasoning', status=None), ResponseOutputMessage(id='msg_6820e444428c8191adb8979b127fd99a01500285876f2f6b', content=[ResponseOutputText(annotations=[], text='Under the silver glow of a sleepy moon, a shy unicorn named Liora tiptoed through a meadow of lullaby flowers that hummed soft, soothing notes. She used her shimmering horn to gather the dreams of every dozing creature, weaving them into twinkling constellations that gently drifted down like snowflakes of stardust. With the world wrapped in a blanket of calm, Liora curled beside a whispering brook and closed her eyes, knowing every heart was now cradled in peaceful dreams.', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=17, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=111, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=128), user=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "# Test f√ºr OpenAI Basics\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o3\", input=\"Tell me a three sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee5bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gpt-4o\", \"o3\"]\n",
    "cvs = [\"cv1\", \"cv2\", \"cv3\"]\n",
    "\n",
    "for model in models:\n",
    "    for cva, cvb in cvs:\n",
    "        response = client.responses.create(model = model, input=input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1\n",
    "\n",
    "Response(\n",
    "    id=\"resp_6820dc9225688191a3a11ad1bca4aee805a0ff69dc4bb2ad\",\n",
    "    created_at=1746984082.0,\n",
    "    error=None,\n",
    "    incomplete_details=None,\n",
    "    instructions=None,\n",
    "    metadata={},\n",
    "    model=\"gpt-4.1-2025-04-14\",\n",
    "    object=\"response\",\n",
    "    output=[\n",
    "        ResponseOutputMessage(\n",
    "            id=\"msg_6820dc92d2a08191a872e65eb422f0f705a0ff69dc4bb2ad\",\n",
    "            content=[\n",
    "                ResponseOutputText(\n",
    "                    annotations=[],\n",
    "                    text=\"Under a velvet sky, a gentle unicorn named Luna galloped through a sparkling forest, leaving trails of stardust behind her. One night, she found a lonely owl who had lost his way, and with a tap of her glowing horn, she lit up the path home. From that day on, Luna and the owl became best friends, watching over the magical forest together every starry night.\",\n",
    "                    type=\"output_text\",\n",
    "                )\n",
    "            ],\n",
    "            role=\"assistant\",\n",
    "            status=\"completed\",\n",
    "            type=\"message\",\n",
    "        )\n",
    "    ],\n",
    "    parallel_tool_calls=True,\n",
    "    temperature=1.0,\n",
    "    tool_choice=\"auto\",\n",
    "    tools=[],\n",
    "    top_p=1.0,\n",
    "    max_output_tokens=None,\n",
    "    previous_response_id=None,\n",
    "    reasoning=Reasoning(effort=None, generate_summary=None, summary=None),\n",
    "    service_tier=\"default\",\n",
    "    status=\"completed\",\n",
    "    text=ResponseTextConfig(format=ResponseFormatText(type=\"text\")),\n",
    "    truncation=\"disabled\",\n",
    "    usage=ResponseUsage(\n",
    "        input_tokens=18,\n",
    "        input_tokens_details=InputTokensDetails(cached_tokens=0),\n",
    "        output_tokens=81,\n",
    "        output_tokens_details=OutputTokensDetails(reasoning_tokens=0),\n",
    "        total_tokens=99,\n",
    "    ),\n",
    "    user=None,\n",
    "    store=True,\n",
    ")\n",
    "\n",
    "# 4o\n",
    "\n",
    "Response(\n",
    "    id=\"resp_6820dd085f1c8191886121c8a7c558530fc7248cab0bd3b2\",\n",
    "    created_at=1746984200.0,\n",
    "    error=None,\n",
    "    incomplete_details=None,\n",
    "    instructions=None,\n",
    "    metadata={},\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    object=\"response\",\n",
    "    output=[\n",
    "        ResponseOutputMessage(\n",
    "            id=\"msg_6820dd08d58881918a06c7f300d017710fc7248cab0bd3b2\",\n",
    "            content=[\n",
    "                ResponseOutputText(\n",
    "                    annotations=[],\n",
    "                    text=\"In the heart of an enchanted forest, there lived a unicorn named Luna who shimmered with stardust. One night, the moon whispered a secret map into her ear, leading her to a hidden grove where dreams sparkled like fireflies. As she danced under the silver light, Luna realized she had the power to make every wish upon a star come true, spreading magic and joy throughout the land.\",\n",
    "                    type=\"output_text\",\n",
    "                )\n",
    "            ],\n",
    "            role=\"assistant\",\n",
    "            status=\"completed\",\n",
    "            type=\"message\",\n",
    "        )\n",
    "    ],\n",
    "    parallel_tool_calls=True,\n",
    "    temperature=1.0,\n",
    "    tool_choice=\"auto\",\n",
    "    tools=[],\n",
    "    top_p=1.0,\n",
    "    max_output_tokens=None,\n",
    "    previous_response_id=None,\n",
    "    reasoning=Reasoning(effort=None, generate_summary=None, summary=None),\n",
    "    service_tier=\"default\",\n",
    "    status=\"completed\",\n",
    "    text=ResponseTextConfig(format=ResponseFormatText(type=\"text\")),\n",
    "    truncation=\"disabled\",\n",
    "    usage=ResponseUsage(\n",
    "        input_tokens=18,\n",
    "        input_tokens_details=InputTokensDetails(cached_tokens=0),\n",
    "        output_tokens=82,\n",
    "        output_tokens_details=OutputTokensDetails(reasoning_tokens=0),\n",
    "        total_tokens=100,\n",
    "    ),\n",
    "    user=None,\n",
    "    store=True,\n",
    ")\n",
    "\n",
    "# o3\n",
    "\n",
    "Response(\n",
    "    id=\"resp_6820e443470c8191835fa06edeac7ff901500285876f2f6b\",\n",
    "    created_at=1746986051.0,\n",
    "    error=None,\n",
    "    incomplete_details=None,\n",
    "    instructions=None,\n",
    "    metadata={},\n",
    "    model=\"o3-2025-04-16\",\n",
    "    object=\"response\",\n",
    "    output=[\n",
    "        ResponseReasoningItem(\n",
    "            id=\"rs_6820e443a6f88191a5fcd5d25f1554a101500285876f2f6b\",\n",
    "            summary=[],\n",
    "            type=\"reasoning\",\n",
    "            status=None,\n",
    "        ),\n",
    "        ResponseOutputMessage(\n",
    "            id=\"msg_6820e444428c8191adb8979b127fd99a01500285876f2f6b\",\n",
    "            content=[\n",
    "                ResponseOutputText(\n",
    "                    annotations=[],\n",
    "                    text=\"Under the silver glow of a sleepy moon, a shy unicorn named Liora tiptoed through a meadow of lullaby flowers that hummed soft, soothing notes. She used her shimmering horn to gather the dreams of every dozing creature, weaving them into twinkling constellations that gently drifted down like snowflakes of stardust. With the world wrapped in a blanket of calm, Liora curled beside a whispering brook and closed her eyes, knowing every heart was now cradled in peaceful dreams.\",\n",
    "                    type=\"output_text\",\n",
    "                )\n",
    "            ],\n",
    "            role=\"assistant\",\n",
    "            status=\"completed\",\n",
    "            type=\"message\",\n",
    "        ),\n",
    "    ],\n",
    "    parallel_tool_calls=True,\n",
    "    temperature=1.0,\n",
    "    tool_choice=\"auto\",\n",
    "    tools=[],\n",
    "    top_p=1.0,\n",
    "    max_output_tokens=None,\n",
    "    previous_response_id=None,\n",
    "    reasoning=Reasoning(effort=\"medium\", generate_summary=None, summary=None),\n",
    "    service_tier=\"default\",\n",
    "    status=\"completed\",\n",
    "    text=ResponseTextConfig(format=ResponseFormatText(type=\"text\")),\n",
    "    truncation=\"disabled\",\n",
    "    usage=ResponseUsage(\n",
    "        input_tokens=17,\n",
    "        input_tokens_details=InputTokensDetails(cached_tokens=0),\n",
    "        output_tokens=111,\n",
    "        output_tokens_details=OutputTokensDetails(reasoning_tokens=0),\n",
    "        total_tokens=128,\n",
    "    ),\n",
    "    user=None,\n",
    "    store=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ad19c",
   "metadata": {},
   "source": [
    "# Uploading files\n",
    "\n",
    "In the example below, we first upload a PDF using the Files API, then reference its file ID in an API request to the model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
